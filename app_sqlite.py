import streamlit as st
import pandas as pd
import time
from datetime import datetime, timedelta
import json
import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏
from modules.database import VGTRKDatabase
from modules.site_parser import SiteParser
from modules.gigachat_client import GigaChatClient
from modules.advanced_logger import AdvancedLogger, LogLevel, get_logger
from modules.scrapy_parser import ScrapyParser  # –ù–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è Sitemap –ø–∞—Ä—Å–∏–Ω–≥–∞
from modules.results_formatter import SitemapResultsFormatter
from app_sqlite_results_cards import ResultsCardsDisplay
from config.settings import GIGACHAT_API_KEY, GIGACHAT_CLIENT_ID

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ñ–∏–ª–∏–∞–ª–æ–≤ –í–ì–¢–†–ö",
    page_icon="üì∫",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤)"""
    return VGTRKDatabase("data/vgtrk_monitoring.db")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if 'parsing_results' not in st.session_state:
    st.session_state.parsing_results = []
if 'current_status' not in st.session_state:
    st.session_state.current_status = "–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ"
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'selected_filials' not in st.session_state:
    st.session_state.selected_filials = []
if 'log_level' not in st.session_state:
    st.session_state.log_level = LogLevel.INFO
if 'logger' not in st.session_state:
    st.session_state.logger = get_logger(st.session_state.log_level)

def log_message(message: str, level: str = "INFO", details: dict = None):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä"""
    st.session_state.logger.log(level.upper(), message, details)

def main():
    st.title("üì∫ –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ñ–∏–ª–∏–∞–ª–æ–≤ –í–ì–¢–†–ö")
    st.markdown("---")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    db = init_database()
    
    # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üè¢ –§–∏–ª–∏–∞–ª—ã", 
        "üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", 
        "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã", 
        "üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
        "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"
    ])
    
    # –í–∫–ª–∞–¥–∫–∞: –§–∏–ª–∏–∞–ª—ã
    with tab1:
        show_filials_tab(db)
    
    # –í–∫–ª–∞–¥–∫–∞: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    with tab2:
        show_monitoring_tab(db)
    
    # –í–∫–ª–∞–¥–∫–∞: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    with tab3:
        show_results_tab(db)
    
    # –í–∫–ª–∞–¥–∫–∞: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    with tab4:
        show_statistics_tab(db)
    
    # –í–∫–ª–∞–¥–∫–∞: –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    with tab5:
        show_settings_tab(db)

def show_filials_tab(db: VGTRKDatabase):
    """–í–∫–ª–∞–¥–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ–∏–ª–∏–∞–ª–∞–º–∏ —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ–π"""
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    from modules.filials_table_editor import FilialsTableEditor
    
    # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã
    table_editor = FilialsTableEditor()
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    table_editor.display_interactive_table()
    
    return  # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π –∫–æ–¥ –Ω–∞ –Ω–æ–≤—ã–π –º–æ–¥—É–ª—å
    
    # –°—Ç–∞—Ä—ã–π –∫–æ–¥ –Ω–∏–∂–µ (–æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è)
    st.header("üè¢ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∏–ª–∏–∞–ª–∞–º–∏")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("–§–∏–ª—å—Ç—Ä—ã")
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –æ–∫—Ä—É–≥–∞–º
        all_filials = db.get_all_filials()
        districts = sorted(list(set(f['federal_district'] for f in all_filials if f.get('federal_district'))))
        districts.insert(0, "–í—Å–µ –æ–∫—Ä—É–≥–∞")
        
        selected_district = st.selectbox(
            "–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥",
            districts,
            help="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"
        )
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        show_active_only = st.checkbox("–¢–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ", value=True)
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–ª–∏—á–∏—é sitemap
        sitemap_filter = st.selectbox(
            "–§–∏–ª—å—Ç—Ä Sitemap",
            ["–í—Å–µ", "–° Sitemap", "–ë–µ–∑ Sitemap"]
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if selected_district == "–í—Å–µ –æ–∫—Ä—É–≥–∞":
            filtered_filials = all_filials
        else:
            filtered_filials = [f for f in all_filials if f['federal_district'] == selected_district]
        
        if show_active_only:
            filtered_filials = [f for f in filtered_filials if f['is_active'] == 1]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä sitemap
        if sitemap_filter == "–° Sitemap":
            filtered_filials = [f for f in filtered_filials if f.get('sitemap_url')]
        elif sitemap_filter == "–ë–µ–∑ Sitemap":
            filtered_filials = [f for f in filtered_filials if f.get('website') and not f.get('sitemap_url')]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ sitemap
        with_sitemap = len([f for f in filtered_filials if f.get('sitemap_url')])
        without_sitemap = len([f for f in filtered_filials if f.get('website') and not f.get('sitemap_url')])
        
        col_stat1, col_stat2 = st.columns(2)
        with col_stat1:
            st.metric("–ù–∞–π–¥–µ–Ω–æ —Ñ–∏–ª–∏–∞–ª–æ–≤", len(filtered_filials))
        with col_stat2:
            st.metric("–° Sitemap", f"{with_sitemap}/{len(filtered_filials)}")
        
        # –ö–Ω–æ–ø–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ CSV
        st.markdown("---")
        if st.button("üì• –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ CSV", use_container_width=True):
            csv_path = Path("../–ì–¢–†–ö/vgtrk_filials_final.csv")
            if not csv_path.exists():
                csv_path = Path("–ì–¢–†–ö/vgtrk_filials_final.csv")
            
            if csv_path.exists():
                count = db.import_filials_from_csv(str(csv_path), clear_existing=False)
                st.success(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {count} —Ñ–∏–ª–∏–∞–ª–æ–≤")
                st.rerun()
            else:
                st.error("‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ö–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞ sitemap
        if st.button("üîç –ù–∞–π—Ç–∏ Sitemap", use_container_width=True,
                     help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ sitemap –¥–ª—è —Ñ–∏–ª–∏–∞–ª–æ–≤ –±–µ–∑ sitemap"):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–ª–∏–∞–ª–æ–≤ –±–µ–∑ sitemap
            without_sitemap = [f for f in filtered_filials
                             if f.get('website') and not f.get('sitemap_url')]
            
            if without_sitemap:
                st.info(f"üîç –ü–æ–∏—Å–∫ sitemap –¥–ª—è {len(without_sitemap)} —Ñ–∏–ª–∏–∞–ª–æ–≤...")
                
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å –ø–æ–∏—Å–∫–∞ sitemap
                from sitemap_finder import find_sitemap_for_filial, save_sitemap_to_db
                
                found_count = 0
                progress_bar = st.progress(0)
                
                for idx, filial in enumerate(without_sitemap[:10]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 —Ñ–∏–ª–∏–∞–ª–∞–º–∏ –∑–∞ —Ä–∞–∑
                    progress_bar.progress((idx + 1) / min(len(without_sitemap), 10))
                    website = filial.get('website')
                    if website:
                        if not website.startswith(('http://', 'https://')):
                            website = f'https://{website}'
                        
                        sitemap_url = find_sitemap_for_filial(website)
                        if sitemap_url:
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                            save_sitemap_to_db(filial['id'], sitemap_url, db_path)
                            found_count += 1
                            st.success(f"‚úÖ {filial['name']}: –Ω–∞–π–¥–µ–Ω {sitemap_url}")
                
                progress_bar.empty()
                if found_count > 0:
                    st.success(f"üéâ –ù–∞–π–¥–µ–Ω–æ {found_count} –Ω–æ–≤—ã—Ö sitemap!")
                    st.rerun()
                else:
                    st.warning("–ù–æ–≤—ã–µ sitemap –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            else:
                st.info("‚úÖ –£ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∏–ª–∏–∞–ª–æ–≤ –µ—Å—Ç—å sitemap –∏–ª–∏ –Ω–µ—Ç —Å–∞–π—Ç–∞")
    
    with col2:
        st.subheader("–°–ø–∏—Å–æ–∫ —Ñ–∏–ª–∏–∞–ª–æ–≤")
        
        # –†–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        edit_mode = st.checkbox("üîß –†–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∞–π—Ç–æ–≤")
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ñ–∏–ª–∏–∞–ª–æ–≤
        if filtered_filials:
            # –ü–æ–ª—É—á–∞–µ–º –∞–¥—Ä–µ—Å–∞ —Å–∞–π—Ç–æ–≤, –∫–æ–¥—ã —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ sitemap_url –∏–∑ –ë–î
            import sqlite3
            db_path = "data/vgtrk_monitoring.db"
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT id, website_url, region_code, sitemap_url FROM filials")
                result = cursor.fetchall()
                websites_dict = {r[0]: r[1] for r in result}
                codes_dict = {r[0]: r[2] for r in result}
                sitemaps_dict = {r[0]: r[3] for r in result}
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–∏–ª–∏–∞–ª–æ–≤ —Å –∞–¥—Ä–µ—Å–∞–º–∏ —Å–∞–π—Ç–æ–≤, –∫–æ–¥–∞–º–∏ –∏ sitemap
            for filial in filtered_filials:
                if filial['id'] in websites_dict:
                    filial['website'] = websites_dict[filial['id']]
                if filial['id'] in codes_dict:
                    filial['region_code'] = codes_dict[filial['id']]
                if filial['id'] in sitemaps_dict:
                    filial['sitemap_url'] = sitemaps_dict[filial['id']]
            
            if edit_mode:
                # –†–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                st.info("üìù –†–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –∏–∑–º–µ–Ω–∏—Ç–µ –∞–¥—Ä–µ—Å–∞ —Å–∞–π—Ç–æ–≤ –∏ sitemap –∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                
                for idx, filial in enumerate(filtered_filials):
                    with st.expander(f"{filial['name']} - {filial.get('region', '')}"):
                        col_e1, col_e2, col_e3 = st.columns([3, 3, 1])
                        
                        with col_e1:
                            # –ü–æ–ª–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∞–π—Ç–∞
                            current_site = filial.get('website', '')
                            new_site = st.text_input(
                                "–ê–¥—Ä–µ—Å —Å–∞–π—Ç–∞",
                                value=current_site or '',
                                key=f"site_{filial['id']}",
                                placeholder="–í–≤–µ–¥–∏—Ç–µ –∞–¥—Ä–µ—Å —Å–∞–π—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: vesti42.ru)"
                            )
                        
                        with col_e2:
                            # –ü–æ–ª–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è sitemap
                            current_sitemap = filial.get('sitemap_url', '')
                            new_sitemap = st.text_input(
                                "Sitemap URL",
                                value=current_sitemap or '',
                                key=f"sitemap_{filial['id']}",
                                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: /sitemap.xml –∏–ª–∏ –ø–æ–ª–Ω—ã–π URL"
                            )
                        
                        with col_e3:
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞
                            code = filial.get('region_code', '')
                            st.metric("–ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞", code if code else "‚Äî")
                        
                        # –ö–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                        if st.button(f"üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", key=f"save_{filial['id']}"):
                            with sqlite3.connect(db_path) as conn:
                                cursor = conn.cursor()
                                if new_site or new_sitemap:
                                    cursor.execute("""
                                        UPDATE filials
                                        SET website_url = ?, sitemap_url = ?
                                        WHERE id = ?
                                    """, (new_site if new_site else None,
                                          new_sitemap if new_sitemap else None,
                                          filial['id']))
                                else:
                                    cursor.execute("""
                                        UPDATE filials
                                        SET website_url = NULL, sitemap_url = NULL
                                        WHERE id = ?
                                    """, (filial['id'],))
                                conn.commit()
                            st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –¥–ª—è {filial['name']}")
                            st.rerun()
            else:
                # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                df = pd.DataFrame(filtered_filials)
                
                # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–¥–æ–±–∞–≤–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–ª–∏—á–∏—è)
                available_columns = []
                desired_columns = ['id', 'name', 'federal_district', 'region_code', 'website', 'sitemap_url', 'is_active']
                for col in desired_columns:
                    if col in df.columns:
                        available_columns.append(col)
                
                df = df[available_columns]
                
                # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                column_mapping = {
                    'id': 'ID',
                    'name': '–ù–∞–∑–≤–∞–Ω–∏–µ',
                    'federal_district': '–û–∫—Ä—É–≥',
                    'region_code': '–ö–æ–¥',
                    'website': '–°–∞–π—Ç',
                    'sitemap_url': 'Sitemap',
                    'is_active': '–ê–∫—Ç–∏–≤–µ–Ω'
                }
                df.rename(columns=column_mapping, inplace=True)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É –°–∞–π—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫
                if '–°–∞–π—Ç' in df.columns:
                    df['–°–∞–π—Ç'] = df['–°–∞–π—Ç'].fillna('–ù–µ—Ç —Å–∞–π—Ç–∞')
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞
                if '–ö–æ–¥' in df.columns:
                    df['–ö–æ–¥'] = df['–ö–æ–¥'].fillna(0).astype(int)
                    df['–ö–æ–¥'] = df['–ö–æ–¥'].apply(lambda x: f"{x:02d}" if x > 0 else "‚Äî")
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É Sitemap —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
                if 'Sitemap' in df.columns:
                    df['Sitemap'] = df['Sitemap'].apply(lambda x: '‚úÖ' if x else '‚ùå')
            
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤—ã–±–æ—Ä–∞
                selected_rows = st.dataframe(
                    df,
                    use_container_width='stretch',
                    hide_index=True,
                    selection_mode="multi-row",
                    on_select="rerun"
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∏–ª–∏–∞–ª—ã
                if selected_rows and selected_rows.selection.rows:
                    st.session_state.selected_filials = [
                        filtered_filials[i] for i in selected_rows.selection.rows
                    ]
                    st.info(f"–í—ã–±—Ä–∞–Ω–æ —Ñ–∏–ª–∏–∞–ª–æ–≤: {len(st.session_state.selected_filials)}")
        else:
            st.info("–§–∏–ª–∏–∞–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

def show_monitoring_tab(db: VGTRKDatabase):
    """–í–∫–ª–∞–¥–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    st.header("üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–∫
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
        
        # –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        st.markdown("### üìä –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–æ–≤")
        log_level_options = {
            "üîç DEBUG - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è": LogLevel.DEBUG,
            "‚ÑπÔ∏è INFO - –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏": LogLevel.INFO,
            "‚ö†Ô∏è WARNING - –¢–æ–ª—å–∫–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è": LogLevel.WARNING,
            "‚ùå ERROR - –¢–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏": LogLevel.ERROR
        }
        
        selected_level = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è",
            options=list(log_level_options.keys()),
            index=1,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é INFO
            help="DEBUG –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, ERROR —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"
        )
        
        new_level = log_level_options[selected_level]
        if new_level != st.session_state.log_level:
            st.session_state.log_level = new_level
            st.session_state.logger.set_level(new_level)
            st.success(f"‚úÖ –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ {new_level.value}")
        
        st.markdown("---")
        
        # –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
        st.markdown("### üîé –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞")
        search_mode_options = {
            "‚ö° –¢–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞": "main_only",
            "üì∞ –ì–ª–∞–≤–Ω–∞—è + –ù–æ–≤–æ—Å—Ç–∏": "main_and_news",
            "üì° RSS –ø–æ–∏—Å–∫ (–Ω–æ–≤–∏–Ω–∫–∞!)": "rss_search",
            "üï∑Ô∏è Sitemap –∞—Ä—Ö–∏–≤ (–≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫)": "sitemap_search"
        }
        
        selected_search_mode = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞",
            options=list(search_mode_options.keys()),
            index=3,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é Sitemap –∞—Ä—Ö–∏–≤
            help="""
            ‚ö° –¢–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–∞—è: –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (10-20x –±—ã—Å—Ç—Ä–µ–µ)
            üì∞ –ì–ª–∞–≤–Ω–∞—è + –ù–æ–≤–æ—Å—Ç–∏: –ø–æ–∏—Å–∫ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –≥–ª–∞–≤–Ω–æ–π –∏ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (5-10x –±—ã—Å—Ç—Ä–µ–µ)
            üì° RSS –ø–æ–∏—Å–∫: —Å—É–ø–µ—Ä-–±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –ø–æ —Å–≤–µ–∂–∏–º –Ω–æ–≤–æ—Å—Ç—è–º –∏–∑ RSS –ª–µ–Ω—Ç—ã
            üï∑Ô∏è Sitemap –∞—Ä—Ö–∏–≤: –ø–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –í–°–ï–ú–£ –∞—Ä—Ö–∏–≤—É —Å–∞–π—Ç–∞ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
            """
        )
        
        search_mode = search_mode_options[selected_search_mode]
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–∏–æ–¥–∞ –¥–ª—è Sitemap –ø–æ–∏—Å–∫–∞
        if search_mode == "sitemap_search":
            st.markdown("### üìÖ –ü–µ—Ä–∏–æ–¥ –ø–æ–∏—Å–∫–∞")
            
            # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –¥–∞—Ç–µ
            date_search_type = st.radio(
                "–¢–∏–ø –ø–æ–∏—Å–∫–∞ –ø–æ –¥–∞—Ç–µ",
                ["–ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä", "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞", "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç"],
                horizontal=True,
                help="–ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä - –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã, –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞ - –≤—ã–±–æ—Ä —á–µ—Ä–µ–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—å, –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç - –≤—ã–±–æ—Ä –ø–µ—Ä–∏–æ–¥–∞ —Å/–ø–æ"
            )
            
            if date_search_type == "–ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä":
                period_options = {
                    "–ó–∞ —Å–µ–≥–æ–¥–Ω—è": 1,
                    "–ó–∞ –≤—á–µ—Ä–∞": 1,  # –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ—Å–æ–±—ã–º –æ–±—Ä–∞–∑–æ–º
                    "–ó–∞ 3 –¥–Ω—è": 3,
                    "–ó–∞ 4 –¥–Ω—è": 4,
                    "–ó–∞ –Ω–µ–¥–µ–ª—é": 7,
                    "–ó–∞ 2 –Ω–µ–¥–µ–ª–∏": 14,
                    "–ó–∞ –º–µ—Å—è—Ü": 30,
                    "–ó–∞ 3 –º–µ—Å—è—Ü–∞": 90
                }
                
                selected_period = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –∞—Ä—Ö–∏–≤–∞",
                    options=list(period_options.keys()),
                    index=3,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞ 4 –¥–Ω—è
                    help="–ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ö–∏–≤—É —Å–∞–π—Ç–∞ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"
                )
                
                search_days = period_options[selected_period]
                
                # –û—Å–æ–±–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è "–ó–∞ –≤—á–µ—Ä–∞"
                if selected_period == "–ó–∞ –≤—á–µ—Ä–∞":
                    specific_date = datetime.now() - timedelta(days=1)
                    search_specific_date = specific_date.date()
                    search_days = None  # –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É
                else:
                    search_specific_date = None
                    
            elif date_search_type == "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞":
                # –ö–∞–ª–µ–Ω–¥–∞—Ä—å –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–∞—Ç—ã
                selected_date = st.date_input(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É –¥–ª—è –ø–æ–∏—Å–∫–∞",
                    value=datetime.now().date() - timedelta(days=2),  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–∑–∞–≤—á–µ—Ä–∞
                    max_value=datetime.now().date(),
                    min_value=datetime.now().date() - timedelta(days=365),
                    help="–ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É"
                )
                
                search_specific_date = selected_date
                search_days = None  # –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É
                
            else:  # –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
                col_date1, col_date2 = st.columns(2)
                
                with col_date1:
                    date_from = st.date_input(
                        "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞",
                        value=datetime.now().date() - timedelta(days=7),
                        max_value=datetime.now().date(),
                        min_value=datetime.now().date() - timedelta(days=365),
                        help="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞"
                    )
                
                with col_date2:
                    date_to = st.date_input(
                        "–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è",
                        value=datetime.now().date(),
                        max_value=datetime.now().date(),
                        min_value=date_from,
                        help="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞"
                    )
                
                # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
                search_days = (date_to - date_from).days + 1
                search_specific_date = None
                search_date_range = (date_from, date_to)
            
            # –û–ø—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GigaChat
            use_gigachat = st.checkbox(
                "ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ GigaChat",
                value=False,
                help="–û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ GigaChat –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–∫–µ–Ω—ã)"
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            if search_specific_date:
                info_msg = f"üï∑Ô∏è Sitemap –ø–æ–∏—Å–∫: —Å—Ç–∞—Ç—å–∏ –∑–∞ {search_specific_date.strftime('%d.%m.%Y')}. "
            else:
                info_msg = f"üï∑Ô∏è Sitemap –ø–æ–∏—Å–∫: –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ –∑–∞ {search_days} –¥–Ω–µ–π. "
            info_msg += '–° –∞–Ω–∞–ª–∏–∑–æ–º GigaChat' if use_gigachat else '–ë–µ–∑ GigaChat (—Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π)'
            st.info(info_msg)
        else:
            search_days = None
            use_gigachat = True  # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–æ–≤ –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º GigaChat
        
        # –û–ø–∏—Å–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        if search_mode == "main_only":
            st.info("üí° –ú–µ—Ç–∞-–ø–æ–∏—Å–∫ –ø–æ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å, 90% —ç–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤")
        elif search_mode == "main_and_news":
            st.info("üí° –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–µ—Ç–∞-–ø–æ–∏—Å–∫: –≤–∫–ª—é—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, 80% —ç–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤")
        elif search_mode == "rss_search":
            st.info("üöÄ RSS –ø–æ–∏—Å–∫: —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏, —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å, 95% —ç–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤!")
        
        st.markdown("---")
        
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è Sitemap
        if search_mode == "sitemap_search":
            st.markdown("### ‚ö° –†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            processing_mode = st.radio(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∏–ª–∏–∞–ª–æ–≤",
                ["üöÄ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)", "üêå –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π (–ø–æ –æ—á–µ—Ä–µ–¥–∏)"],
                index=0,
                help="""
                üöÄ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ 20 —Ñ–∏–ª–∏–∞–ª–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ (–≤ 5-10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ)
                üêå –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π: —Ñ–∏–ª–∏–∞–ª—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (—Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
                """
            )
            
            if processing_mode == "üöÄ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)":
                max_concurrent = st.slider(
                    "–ú–∞–∫—Å. –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π",
                    min_value=5,
                    max_value=50,
                    value=20,
                    help="–ë–æ–ª—å—à–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π = –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –≤—ã—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —Å–µ—Ç—å"
                )
                use_async = True
            else:
                max_concurrent = 1
                use_async = False
        else:
            use_async = False
            max_concurrent = 1
        
        st.markdown("---")
        
        # –í—ã–±–æ—Ä —Ñ–∏–ª–∏–∞–ª–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        monitoring_mode = st.radio(
            "–†–µ–∂–∏–º –≤—ã–±–æ—Ä–∞ —Ñ–∏–ª–∏–∞–ª–æ–≤",
            ["–í—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ", "–ü–æ –æ–∫—Ä—É–≥—É", "–í—ã–±—Ä–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é"]
        )
        
        filials_to_monitor = []
        
        if monitoring_mode == "–í—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ":
            filials_to_monitor = db.get_all_filials(active_only=True)
        
        elif monitoring_mode == "–ü–æ –æ–∫—Ä—É–≥—É":
            all_filials = db.get_all_filials()
            districts = sorted(list(set(f['federal_district'] for f in all_filials)))
            selected_districts = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –æ–∫—Ä—É–≥–∞",
                districts,
                default=["–°–§–û"] if "–°–§–û" in districts else []
            )
            for district in selected_districts:
                filials_to_monitor.extend(db.get_filials_by_district(district))
        
        elif monitoring_mode == "–í—ã–±—Ä–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é":
            if st.session_state.selected_filials:
                filials_to_monitor = st.session_state.selected_filials
            else:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∏–ª–∏–∞–ª—ã –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–§–∏–ª–∏–∞–ª—ã'")
        
        st.metric("–§–∏–ª–∏–∞–ª–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞", len(filials_to_monitor))
        
        # –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        st.markdown("---")
        st.subheader("üîé –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
        
        search_queries = db.get_search_queries()
        if search_queries:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            categories = {}
            for q in search_queries:
                cat = q.get('category', '–±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(q)
            
            selected_queries = []
            for cat, queries in categories.items():
                st.write(f"**{cat.capitalize()}:**")
                for q in queries:
                    if st.checkbox(
                        q['query_text'], 
                        key=f"query_{q['id']}",
                        help=q.get('description', '')
                    ):
                        selected_queries.append(q)
        else:
            st.info("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
            if st.button("–î–æ–±–∞–≤–∏—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã"):
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                standard_queries = [
                    ("–í–ì–¢–†–ö", "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π", "–£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≥–æ–ª–æ–≤–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏"),
                    ("–≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä", "—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ", "–î–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞"),
                    ("–º–µ—Å—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", "—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ", "–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è")
                ]
                for query, cat, desc in standard_queries:
                    db.add_search_query(query, cat, desc)
                st.rerun()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ GigaChat
        st.markdown("---")
        st.subheader("ü§ñ GigaChat")
        gigachat_model = st.selectbox(
            "–ú–æ–¥–µ–ª—å", 
            ["GigaChat", "GigaChat-Pro"],
            index=0
        )
        
        temperature = st.slider(
            "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 
            0.1, 1.0, 0.7, 0.1,
            help="–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤"
        )
        
        # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
        st.markdown("---")
        start_button = st.button(
            "üöÄ –ù–∞—á–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
            type="primary",
            disabled=st.session_state.processing or not filials_to_monitor,
            use_container_width='stretch'
        )
        
        if st.session_state.processing:
            stop_button = st.button(
                "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å",
                use_container_width='stretch'
            )
            if stop_button:
                st.session_state.processing = False
                st.rerun()
    
    with col2:
        st.subheader("üìã –ü—Ä–æ—Ü–µ—Å—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
        
        # –°—Ç–∞—Ç—É—Å –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å
        status_container = st.container()
        with status_container:
            if st.session_state.processing:
                st.info(f"üîÑ {st.session_state.current_status}")
                progress_bar = st.progress(0)
            else:
                st.info(f"üí§ {st.session_state.current_status}")
        
        # –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        if start_button and filials_to_monitor:
            st.session_state.processing = True
            st.session_state.current_status = "–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞..."
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å —Ä–µ–∂–∏–º–æ–º –ø–æ–∏—Å–∫–∞
            monitoring_params = {
                'db': db,
                'filials': filials_to_monitor,
                'queries': selected_queries if 'selected_queries' in locals() else [],
                'model': gigachat_model,
                'temperature': temperature,
                'search_mode': search_mode
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Sitemap –ø–æ–∏—Å–∫–∞
            if search_mode == "sitemap_search":
                monitoring_params['search_days'] = search_days
                monitoring_params['use_gigachat'] = use_gigachat
                monitoring_params['search_specific_date'] = search_specific_date if 'search_specific_date' in locals() else None
                monitoring_params['search_date_range'] = search_date_range if 'search_date_range' in locals() else None
                monitoring_params['use_async'] = use_async if 'use_async' in locals() else False
                monitoring_params['max_concurrent'] = max_concurrent if 'max_concurrent' in locals() else 1
            
            # –í—ã–±–∏—Ä–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
            if monitoring_params.get('use_async') and search_mode == "sitemap_search":
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                process_monitoring_async_wrapper(**monitoring_params)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                process_monitoring(**monitoring_params)
        
        # –õ–æ–≥–∏
        st.markdown("---")
        st.subheader("üìù –õ–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        
        # –ö–æ–Ω—Ç—Ä–æ–ª—å –ª–æ–≥–æ–≤
        col_log1, col_log2, col_log3 = st.columns([2, 1, 1])
        with col_log1:
            log_filter = st.selectbox(
                "–§–∏–ª—å—Ç—Ä –ª–æ–≥–æ–≤",
                ["–í—Å–µ", "DEBUG", "INFO", "WARNING", "ERROR"],
                help="–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏ –ø–æ —É—Ä–æ–≤–Ω—é"
            )
        with col_log2:
            if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥–∏"):
                st.session_state.logger.clear_old_logs(keep_last=0)
                st.rerun()
        with col_log3:
            if st.button("üíæ –≠–∫—Å–ø–æ—Ä—Ç –ª–æ–≥–æ–≤"):
                export_path = f"logs/export_{datetime.now():%Y%m%d_%H%M%S}.json"
                Path("logs").mkdir(exist_ok=True)
                st.session_state.logger.export_logs(export_path)
                st.success(f"–õ–æ–≥–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {export_path}")
        
        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –ª–æ–≥–æ–≤
        log_container = st.container(height=400)
        with log_container:
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏
            filter_level = log_filter if log_filter != "–í—Å–µ" else None
            logs = st.session_state.logger.get_logs(level_filter=filter_level, limit=100)
            
            for log in reversed(logs):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É
                timestamp = log['timestamp']
                message = log['message']
                level = log['level']
                details = log.get('details', {})
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è
                if level == "ERROR":
                    st.error(f"‚ùå [{timestamp}] {message}")
                elif level == "WARNING":
                    st.warning(f"‚ö†Ô∏è [{timestamp}] {message}")
                elif level == "DEBUG" and details:
                    # –î–ª—è DEBUG –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏
                    with st.expander(f"üîç [{timestamp}] {message}"):
                        for key, value in details.items():
                            st.text(f"  {key}: {value}")
                elif level == "INFO":
                    # –û—Å–æ–±–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ INFO —Å–æ–æ–±—â–µ–Ω–∏–π
                    if "‚úÖ" in message:
                        st.success(f"‚úÖ [{timestamp}] {message}")
                    elif "‚ùå" in message:
                        st.error(f"‚ùå [{timestamp}] {message}")
                    elif "üìÑ" in message and details.get('text_preview'):
                        # –ü–∞—Ä—Å–∏–Ω–≥ —Å –ü–û–î–†–û–ë–ù–´–ú –ø—Ä–µ–≤—å—é —Ç–µ–∫—Å—Ç–∞
                        with st.expander(f"üìÑ [{timestamp}] {message}", expanded=True):
                            st.text(f"URL: {details.get('url', '–Ω–µ —É–∫–∞–∑–∞–Ω')}")
                            st.text("–ü—Ä–µ–≤—å—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å–∞–π—Ç–∞ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
                            # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                            preview_text = details['text_preview']
                            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
                            formatted_preview = "\n".join([
                                line.strip() for line in preview_text.split("\n")
                                if line.strip()
                            ][:10])  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –Ω–µ–ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫
                            st.text_area(
                                "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:",
                                value=formatted_preview,
                                height=200,
                                disabled=True
                            )
                    elif "üìã" in message and details.get('fragment'):
                        # –ù–∞–π–¥–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                        with st.expander(f"üìã [{timestamp}] {message}"):
                            st.text("–ù–∞–π–¥–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç:")
                            st.code(details['fragment'], language=None)
                    elif "ü§ñ" in message and details.get('analysis'):
                        # –û—Ç–≤–µ—Ç GigaChat
                        with st.expander(f"ü§ñ [{timestamp}] {message}"):
                            st.text(f"–ó–∞–ø—Ä–æ—Å: {details.get('query', '–Ω–µ —É–∫–∞–∑–∞–Ω')}")
                            st.text("–û—Ç–≤–µ—Ç GigaChat:")
                            st.info(details['analysis'])
                    elif details:
                        # –û–±—â–∏–π —Å–ª—É—á–∞–π —Å –¥–µ—Ç–∞–ª—è–º–∏
                        with st.expander(f"‚ÑπÔ∏è [{timestamp}] {message}"):
                            for key, value in details.items():
                                st.text(f"  {key}: {value}")
                    else:
                        st.info(f"‚ÑπÔ∏è [{timestamp}] {message}")
                else:
                    st.text(f"[{timestamp}] {message}")

def process_monitoring_async_wrapper(db: VGTRKDatabase, filials: list, queries: list, model: str, temperature: float,
                                    search_mode: str = "main_only", search_days: int = None, use_gigachat: bool = True,
                                    search_specific_date = None, search_date_range = None,
                                    use_async: bool = False, max_concurrent: int = 20):
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    
    from app_sqlite_async import run_async_monitoring_streamlit
    
    logger = st.session_state.logger
    logger.log("INFO", f"–ó–∞–ø—É—Å–∫ –ê–°–ò–ù–•–†–û–ù–ù–û–ì–û –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å {max_concurrent} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏")
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    search_period = None
    if search_specific_date:
        search_period = f"–î–∞—Ç–∞: {search_specific_date}"
    elif search_days:
        search_period = f"–ó–∞ {search_days} –¥–Ω–µ–π"
    elif search_date_range:
        date_from, date_to = search_date_range
        search_period = f"–° {date_from} –ø–æ {date_to}"
    else:
        search_period = "–¢–µ–∫—É—â–∏–π –¥–µ–Ω—å"
    
    session_id = None
    if hasattr(db, 'start_monitoring_session'):
        session_id = db.start_monitoring_session(
            session_name=f"–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            search_mode=f"{search_mode}_async",
            search_period=search_period,
            search_date=str(search_specific_date) if search_specific_date else None
        )
        logger.log("INFO", f"–°–æ–∑–¥–∞–Ω–∞ —Å–µ—Å—Å–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ #{session_id}")
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
    progress_placeholder = st.empty()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        stats = run_async_monitoring_streamlit(
            db=db,
            filials=filials,
            queries=queries,
            search_days=search_days or 7,
            max_concurrent=max_concurrent,
            session_id=session_id,
            progress_placeholder=progress_placeholder
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        st.session_state.processing = False
        st.session_state.current_status = "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω"
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.log("INFO", f"‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {stats['total_time']:.1f} —Å–µ–∫")
        logger.log("INFO", f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_filials']} —Ñ–∏–ª–∏–∞–ª–æ–≤")
        logger.log("INFO", f"–£—Å–ø–µ—à–Ω–æ: {stats['success_count']}, –û—à–∏–±–æ–∫: {stats['error_count']}, –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö: {stats['no_data_count']}")
        logger.log("INFO", f"–ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {stats['total_articles']}")
        logger.log("INFO", f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ñ–∏–ª–∏–∞–ª: {stats['avg_time_per_filial']:.2f} —Å–µ–∫")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é
        if session_id and hasattr(db, 'update_monitoring_session'):
            db.update_monitoring_session(
                session_id,
                filials_count=stats['total_filials'],
                queries_count=len(queries),
                results_count=stats['results_saved'],
                status='completed'
            )
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        progress_placeholder.success(f"""
        ‚úÖ **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!**
        
        - –û–±—â–µ–µ –≤—Ä–µ–º—è: **{stats['total_time']:.1f} —Å–µ–∫—É–Ω–¥**
        - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∏–ª–∏–∞–ª–æ–≤: **{stats['total_filials']}**
        - –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: **{stats['total_filials']/stats['total_time']:.2f} —Ñ–∏–ª–∏–∞–ª–æ–≤/—Å–µ–∫**
        - –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: **{stats['total_articles']}**
        
        –£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º —Ä–µ–∂–∏–º–æ–º: **~{max_concurrent/2:.0f}x**
        """)
        
    except Exception as e:
        logger.log("ERROR", f"–û—à–∏–±–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {str(e)}")
        st.session_state.processing = False
        st.session_state.current_status = f"–û—à–∏–±–∫–∞: {str(e)}"
        
        if session_id and hasattr(db, 'update_monitoring_session'):
            db.update_monitoring_session(
                session_id,
                status='error',
                error_message=str(e)
            )

def process_monitoring(db: VGTRKDatabase, filials: list, queries: list, model: str, temperature: float,
                      search_mode: str = "main_only", search_days: int = None, use_gigachat: bool = True,
                      search_specific_date = None, search_date_range = None,
                      use_async: bool = False, max_concurrent: int = 1):
    """–ü—Ä–æ—Ü–µ—Å—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ñ–∏–ª–∏–∞–ª–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏ –ø–æ–∏—Å–∫–∞ –≤–∫–ª—é—á–∞—è Sitemap"""
    try:
        logger = st.session_state.logger
        logger.log("INFO", "–ù–∞—á–∞–ª–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ñ–∏–ª–∏–∞–ª–æ–≤ –í–ì–¢–†–ö")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        search_period = None
        if search_specific_date:
            search_period = f"–î–∞—Ç–∞: {search_specific_date}"
        elif search_days:
            search_period = f"–ó–∞ {search_days} –¥–Ω–µ–π"
        elif search_date_range:
            date_from, date_to = search_date_range
            search_period = f"–° {date_from} –ø–æ {date_to}"
        else:
            search_period = "–¢–µ–∫—É—â–∏–π –¥–µ–Ω—å"
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É —Å–µ—Å—Å–∏–π
        if hasattr(db, 'start_monitoring_session'):
            session_id = db.start_monitoring_session(
                session_name=f"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                search_mode=search_mode,
                search_period=search_period,
                search_date=str(search_specific_date) if search_specific_date else None
            )
            logger.log("INFO", f"–°–æ–∑–¥–∞–Ω–∞ —Å–µ—Å—Å–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ #{session_id}")
        else:
            session_id = None
            logger.log("WARNING", "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–µ—Å—Å–∏–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏
        session_stats = {
            'total_checked': 0,
            'successful': 0,
            'errors': 0,
            'total_time': 0,
            'total_tokens_used': 0,
            'avg_response_time': 0,
            'avg_page_size': 0
        }
        
        session_start = time.time()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å —É—Ä–æ–≤–Ω–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        site_parser = SiteParser(log_level=st.session_state.log_level)
        gigachat_client = GigaChatClient(
            GIGACHAT_API_KEY,
            GIGACHAT_CLIENT_ID,
            model,
            temperature,
            log_level=st.session_state.log_level
        )
        
        total_filials = len(filials)
        search_mode_names = {
            "main_only": "–¢–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞",
            "main_and_news": "–ì–ª–∞–≤–Ω–∞—è + –ù–æ–≤–æ—Å—Ç–∏",
            "rss_search": "RSS –ª–µ–Ω—Ç–∞",
            "sitemap_search": f"Sitemap –∞—Ä—Ö–∏–≤ ({search_days} –¥–Ω–µ–π)"
        }
        logger.log("INFO", f"–§–∏–ª–∏–∞–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {total_filials} | –†–µ–∂–∏–º: {search_mode_names.get(search_mode, search_mode)}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ScrapyParser –¥–ª—è Sitemap —Ä–µ–∂–∏–º–∞
        if search_mode == "sitemap_search":
            scrapy_parser = ScrapyParser(logger=logger)
        
        response_times = []
        page_sizes = []
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª–∏–∞–ª–∞
        for idx, filial in enumerate(filials):
            if not st.session_state.processing:
                logger.log("WARNING", "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            
            filial_name = filial['name']
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º website_url –∏–∑ –ë–î, –ø–æ—Ç–æ–º website
            website = filial.get('website_url') or filial.get('website', '')
            
            # –ü–æ–ª—É—á–∞–µ–º sitemap_url –∏–∑ –ë–î –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –ø–∞—Ä—Å–µ—Ä
            sitemap_url = None
            if 'id' in filial:
                # –ü–æ–ª—É—á–∞–µ–º sitemap_url –∏–∑ –ë–î
                filial_full = db.get_filial_by_id(filial['id'])
                if filial_full:
                    sitemap_url = filial_full.get('sitemap_url')
                    filial['sitemap_url'] = sitemap_url  # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            
            if not website:
                logger.log("WARNING", f"{filial_name}: –Ω–µ—Ç —Å–∞–π—Ç–∞")
                session_stats['errors'] += 1
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª –µ—Å–ª–∏ –Ω–µ—Ç (–Ω–æ –Ω–µ –¥–ª—è telegram —Å—Å—ã–ª–æ–∫)
            if not website.startswith(('http://', 'https://', 'vk.com')):
                if website.startswith('t.me/'):
                    website = f"https://{website}"
                elif not website.startswith(('http://', 'https://')):
                    website = f"https://{website}"
            
            logger.log("INFO", f"–ü—Ä–æ–≤–µ—Ä–∫–∞ {idx+1}/{total_filials}: {filial_name}")
            st.session_state.current_status = f"–ü—Ä–æ–≤–µ—Ä–∫–∞ {idx+1}/{total_filials}: {filial_name}"
            
            try:
                # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
                if search_mode == "sitemap_search":
                    # Sitemap —Ä–µ–∂–∏–º - –≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∞—Ä—Ö–∏–≤—É
                    logger.log("INFO", f"üï∑Ô∏è Sitemap –ø–æ–∏—Å–∫ –¥–ª—è {filial_name} –∑–∞ {search_days} –¥–Ω–µ–π")
                    
                    keywords = [q['query_text'] for q in queries]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä—è–º–æ–π sitemap URL –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                    sitemap_url = filial.get('sitemap_url')
                    if sitemap_url:
                        logger.log("INFO", f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π sitemap URL: {sitemap_url}")
                    
                    # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Sitemap
                    if search_specific_date:
                        # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
                        sitemap_results = scrapy_parser.search_with_sitemap_date(
                            website,
                            keywords,
                            search_date=search_specific_date,
                            max_articles=150,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –¥–∞—Ç—ã
                            sitemap_url=sitemap_url
                        )
                    else:
                        # –û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥
                        sitemap_results = scrapy_parser.search_with_sitemap(
                            website,
                            keywords,
                            days=search_days,
                            max_articles=50,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                            sitemap_url=sitemap_url,  # –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä—è–º–æ–π URL –µ—Å–ª–∏ –µ—Å—Ç—å
                            date_from=search_date_range[0] if search_date_range else None,
                            date_to=search_date_range[1] if search_date_range else None
                        )
                    
                    session_stats['total_checked'] += 1
                    
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º parsed_content –∏ parse_metrics –¥–ª—è —Ä–µ–∂–∏–º–∞ sitemap
                    parsed_content = None  # Sitemap —Ä–µ–∂–∏–º –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç parsed_content
                    parse_metrics = {'mode': 'sitemap', 'articles_checked': len(sitemap_results) if sitemap_results else 0}
                    
                    if sitemap_results:
                        logger.log("INFO", f"üìä {filial_name}: –Ω–∞–π–¥–µ–Ω–æ {len(sitemap_results)} —Å—Ç–∞—Ç–µ–π –≤ –∞—Ä—Ö–∏–≤–µ")
                        
                        if use_gigachat:
                            # –†–µ–∂–∏–º —Å GigaChat - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–µ
                            for query in queries:
                                query_text = query['query_text']
                                
                                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
                                relevant_articles = [
                                    article for article in sitemap_results
                                    if query_text.lower() in ' '.join(article.get('keywords', [])).lower()
                                ]
                                
                                if relevant_articles:
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º SitemapResultsFormatter –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                                    formatter = SitemapResultsFormatter()
                                    formatted_results = formatter.format_sitemap_results(
                                        relevant_articles,
                                        filial_name,
                                        query_text,
                                        max_display=10
                                    )
                                    
                                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è GigaChat
                                    analysis_text = formatter.format_for_gigachat(
                                        formatted_results['articles'],
                                        filial_name,
                                        query_text
                                    )
                                    
                                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GigaChat
                                    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ —Å —Å–∞–π—Ç–∞ {filial_name}.
                                    –û–ø—Ä–µ–¥–µ–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ —Ç–µ–º–µ '{query_text}'.
                                    –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π."""
                                    
                                    analysis, gigachat_metrics = gigachat_client.analyze_content(
                                        analysis_text[:3000],
                                        prompt
                                    )
                                    
                                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –¥–µ—Ç–∞–ª—è–º–∏ —Å—Ç–∞—Ç–µ–π
                                    result = {
                                        'filial_id': filial['id'],
                                        'search_query_id': query['id'],
                                        'url': website,
                                        'page_title': filial_name,
                                        'content': formatted_results['content'],
                                        'gigachat_analysis': analysis,
                                        'relevance_score': min(formatted_results['total_count'] / 10, 1.0),
                                        'status': 'success',
                                        'search_mode': 'sitemap',
                                        'articles': formatted_results['articles'],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ —Å—Ç–∞—Ç–µ–π
                                        'metrics': {
                                            'articles_found': formatted_results['total_count'],
                                            'search_days': search_days,
                                            'gigachat_metrics': gigachat_metrics
                                        }
                                    }
                                    db.save_monitoring_result(filial['id'], result, session_id)
                                    
                                    logger.log("INFO", f"‚úÖ {filial_name}: –Ω–∞–π–¥–µ–Ω–æ {formatted_results['total_count']} —Å—Ç–∞—Ç–µ–π –¥–ª—è '{query_text}'")
                                    session_stats['successful'] += 1
                                    session_stats['total_tokens_used'] += gigachat_metrics.get('total_tokens', 0)
                                else:
                                    logger.log("INFO", f"‚ùå {filial_name}: '{query_text}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∞—Ä—Ö–∏–≤–µ –∑–∞ {search_days} –¥–Ω–µ–π")
                        else:
                            # –†–µ–∂–∏–º –±–µ–∑ GigaChat - –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
                            for query in queries:
                                query_text = query['query_text']
                                
                                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
                                relevant_articles = [
                                    article for article in sitemap_results
                                    if query_text.lower() in ' '.join(article.get('keywords', [])).lower()
                                ]
                                
                                if relevant_articles:
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º SitemapResultsFormatter –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                                    formatter = SitemapResultsFormatter()
                                    formatted_results = formatter.format_sitemap_results(
                                        relevant_articles,
                                        filial_name,
                                        query_text,
                                        max_display=10
                                    )
                                    
                                    result = {
                                        'filial_id': filial['id'],
                                        'search_query_id': query['id'],
                                        'url': website,
                                        'page_title': filial_name,
                                        'content': formatted_results['content'],
                                        'gigachat_analysis': f"–ù–∞–π–¥–µ–Ω–æ {formatted_results['total_count']} —Å—Ç–∞—Ç–µ–π (–±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ GigaChat)",
                                        'relevance_score': min(formatted_results['total_count'] / 10, 1.0),
                                        'status': 'success',
                                        'search_mode': 'sitemap_no_ai',
                                        'articles': formatted_results['articles'],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ —Å—Ç–∞—Ç–µ–π
                                        'metrics': {
                                            'articles_found': formatted_results['total_count'],
                                            'search_days': search_days
                                        }
                                    }
                                    db.save_monitoring_result(filial['id'], result, session_id)
                                    
                                    logger.log("INFO", f"üìã {filial_name}: –Ω–∞–π–¥–µ–Ω–æ {formatted_results['total_count']} —Å—Ç–∞—Ç–µ–π –¥–ª—è '{query_text}' (–±–µ–∑ GigaChat)")
                                    session_stats['successful'] += 1
                    else:
                        # –ï—Å–ª–∏ sitemap_results –ø—É—Å—Ç–æ–π, —ç—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å –¥–≤–µ —Å–∏—Ç—É–∞—Ü–∏–∏:
                        # 1. Sitemap –Ω–µ –Ω–∞–π–¥–µ–Ω –≤–æ–æ–±—â–µ (—Ä–µ–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞)
                        # 2. Sitemap –Ω–∞–π–¥–µ–Ω, –Ω–æ –Ω–µ—Ç —Å—Ç–∞—Ç–µ–π —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (–Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –Ω–∞–π–¥–µ–Ω sitemap
                        if scrapy_parser.find_sitemap(website, sitemap_url):
                            # Sitemap –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
                            logger.log("INFO", f"üìä {filial_name}: Sitemap –æ–±—Ä–∞–±–æ—Ç–∞–Ω, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                            for query in queries:
                                result = {
                                    'filial_id': filial['id'],
                                    'search_query_id': query['id'],
                                    'url': website,
                                    'page_title': filial_name,
                                    'content': "Sitemap –æ–±—Ä–∞–±–æ—Ç–∞–Ω",
                                    'gigachat_analysis': f"–í –∞—Ä—Ö–∏–≤–µ –∑–∞ {search_days} –¥–Ω–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º '{query['query_text']}'",
                                    'relevance_score': 0.0,
                                    'status': 'no_data',
                                    'search_mode': 'sitemap',
                                    'articles': [],  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
                                    'metrics': {
                                        'articles_found': 0,
                                        'search_days': search_days,
                                        'sitemap_found': True
                                    }
                                }
                                db.save_monitoring_result(filial['id'], result, session_id)
                            
                            # –≠—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞, –∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            session_stats['total_checked'] += 1
                        else:
                            # –†–µ–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ - sitemap –Ω–µ –Ω–∞–π–¥–µ–Ω
                            logger.log("WARNING", f"‚ö†Ô∏è {filial_name}: Sitemap –Ω–µ –Ω–∞–π–¥–µ–Ω")
                            session_stats['errors'] += 1
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É
                            result = {
                                'filial_id': filial['id'],
                                'url': website,
                                'status': 'error',
                                'error_message': 'Sitemap –Ω–µ –Ω–∞–π–¥–µ–Ω',
                                'search_mode': 'sitemap'
                            }
                            db.save_monitoring_result(filial['id'], result, session_id)
                        
                        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–∫–∏
                        parse_metrics = {'mode': 'sitemap'}
                        parsed_content = None
                        
                elif search_mode == "rss_search":
                    # RSS —Ä–µ–∂–∏–º
                    rss_data, parse_metrics = site_parser.parse_rss_feed(website)
                    
                    if rss_data:
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑ RSS
                        parsed_content = f"=== RSS –õ–ï–ù–¢–ê {filial_name} ===\n"
                        parsed_content += f"–ö–∞–Ω–∞–ª: {rss_data.get('channel_title', '')}\n"
                        parsed_content += f"–û–ø–∏—Å–∞–Ω–∏–µ: {rss_data.get('channel_description', '')}\n\n"
                        
                        for item in rss_data.get('items', []):
                            parsed_content += f"--- –ù–û–í–û–°–¢–¨ ---\n"
                            parsed_content += f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {item['title']}\n"
                            parsed_content += f"–û–ø–∏—Å–∞–Ω–∏–µ: {item['description']}\n"
                            parsed_content += f"–°—Å—ã–ª–∫–∞: {item['link']}\n"
                            parsed_content += f"–î–∞—Ç–∞: {item['pubDate']}\n\n"
                    else:
                        parsed_content = None
                else:
                    # –ú–µ—Ç–∞-–ø–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∂–∏–º
                    include_news = (search_mode == "main_and_news")
                    parsed_content, parse_metrics = site_parser.parse_meta_data(website, include_news=include_news)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                if parse_metrics.get('response_time'):
                    response_times.append(parse_metrics['response_time'])
                if parse_metrics.get('page_size_kb'):
                    page_sizes.append(parse_metrics['page_size_kb'])
                
                # –î–ª—è —Ä–µ–∂–∏–º–∞ sitemap_search —Å—á–µ—Ç—á–∏–∫ —É–∂–µ —É–≤–µ–ª–∏—á–µ–Ω –≤—ã—à–µ, –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º
                if search_mode != "sitemap_search":
                    session_stats['total_checked'] += 1
                
                if parsed_content:
                    # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                    if search_mode == "rss_search":
                        items_count = parse_metrics.get('items_count', 0)
                        logger.log("INFO", f"üì° {filial_name}: RSS –ø–æ–ª—É—á–µ–Ω ({items_count} –Ω–æ–≤–æ—Å—Ç–µ–π)", {
                            "rss_url": parse_metrics.get('rss_url'),
                            "url": website,
                            "mode": "rss_search"
                        })
                    else:
                        pages_count = parse_metrics.get('pages_parsed', 1)
                        headers_count = parse_metrics.get('headers_count', 0)
                        meta_tags_count = parse_metrics.get('meta_tags_count', 0)
                        
                        preview_length = 500  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
                        text_preview = parsed_content[:preview_length]
                        if len(parsed_content) > preview_length:
                            text_preview += f"\n... (–µ—â—ë {len(parsed_content) - preview_length} —Å–∏–º–≤–æ–ª–æ–≤)"
                        
                        logger.log("INFO", f"üìÑ {filial_name}: –ú–µ—Ç–∞-–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã (—Å—Ç—Ä–∞–Ω–∏—Ü: {pages_count}, –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {headers_count}, –º–µ—Ç–∞-—Ç–µ–≥–æ–≤: {meta_tags_count})", {
                            "text_preview": text_preview,
                            "url": website,
                            "mode": "meta_search"
                        })
                    
                    # –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    keywords = [q['query_text'] for q in queries]
                    search_results = site_parser.search_keywords(parsed_content, keywords)
                    
                    # –ê–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                    for query in queries:
                        query_text = query['query_text']
                        query_results = search_results.get(query_text, {})
                        
                        # –î–ª—è –º–µ—Ç–∞-–ø–æ–∏—Å–∫–∞ –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º GigaChat –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        logger.log_search_results(filial_name, query_text, query_results)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                        if query_results.get('occurrences', 0) > 0:
                            contexts = query_results.get('contexts', [])
                            if contexts:
                                first_context = contexts[0][:150] if contexts[0] else ""
                                logger.log("INFO", f"üìã {filial_name}: –ù–∞–π–¥–µ–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è '{query_text}'", {
                                    "fragment": first_context.replace("**", "")
                                })
                        
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ GigaChat –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        logger.log("DEBUG", f"–ú–µ—Ç–∞-–ø–æ–∏—Å–∫: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ GigaChat –¥–ª—è '{query_text}'")
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
                        –û–ø—Ä–µ–¥–µ–ª–∏, –µ—Å—Ç—å –ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–µ–º—ã '{query_text}'.
                        –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–∫–ª—é—á–∞—é—Ç: –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü, –æ–ø–∏—Å–∞–Ω–∏—è, –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, H1-H3 –∑–∞–≥–æ–ª–æ–≤–∫–∏.
                        –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ: –Ω–∞–π–¥–µ–Ω–æ/–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏ —á—Ç–æ –∏–º–µ–Ω–Ω–æ.
                        
                        –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:"""
                        
                        analysis, gigachat_metrics = gigachat_client.analyze_content(
                            parsed_content[:3000],
                            prompt
                        )
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ GigaChat
                        logger.log_gigachat_analysis(filial_name, gigachat_metrics)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç GigaChat
                        if analysis and not analysis.startswith("–û—à–∏–±–∫–∞"):
                            analysis_preview = analysis[:200] + "..." if len(analysis) > 200 else analysis
                            logger.log("INFO", f"ü§ñ GigaChat –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {filial_name}", {
                                "analysis": analysis_preview,
                                "query": query_text,
                                "mode": "meta_" + search_mode
                            })
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—à–µ–ª –ª–∏ GigaChat —á—Ç–æ-—Ç–æ
                            found_by_gigachat = not any(phrase in analysis.lower() for phrase in
                                ["–Ω–µ –Ω–∞–π–¥–µ–Ω", "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω", "–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç", "–Ω–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π"])
                            
                            if found_by_gigachat:
                                # GigaChat —á—Ç–æ-—Ç–æ –Ω–∞—à–µ–ª
                                result = {
                                    'filial_id': filial['id'],
                                    'search_query_id': query['id'],
                                    'url': website,
                                    'page_title': filial_name,
                                    'content': parsed_content[:1000],
                                    'gigachat_analysis': analysis,
                                    'relevance_score': 0.7 if query_results.get('occurrences', 0) == 0 else min(query_results['occurrences'] / 10, 1.0),
                                    'status': 'success',
                                    'search_mode': search_mode,
                                    'metrics': {
                                        'parse_metrics': parse_metrics,
                                        'search_results': query_results,
                                        'gigachat_metrics': gigachat_metrics
                                    }
                                }
                                db.save_monitoring_result(filial['id'], result, session_id)
                                
                                if query_results.get('occurrences', 0) > 0:
                                    logger.log("INFO", f"‚úÖ {filial_name}: –Ω–∞–π–¥–µ–Ω–æ '{query_text}' –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ({query_results['occurrences']} —Ä–∞–∑)")
                                else:
                                    logger.log("INFO", f"‚úÖ {filial_name}: GigaChat –Ω–∞—à–µ–ª —É–ø–æ–º–∏–Ω–∞–Ω–∏—è '{query_text}' –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
                                session_stats['successful'] += 1
                            else:
                                # GigaChat –Ω–µ –Ω–∞—à–µ–ª –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                                logger.log("INFO", f"‚ùå {filial_name}: '{query_text}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö", {
                                    "searched_in": f"{parse_metrics.get('pages_parsed', 1)} —Å—Ç—Ä–∞–Ω–∏—Ü, {parse_metrics.get('headers_count', 0)} –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤",
                                    "url": website,
                                    "mode": "meta_" + search_mode
                                })
                                
                                result = {
                                    'filial_id': filial['id'],
                                    'search_query_id': query['id'],
                                    'url': website,
                                    'status': 'no_data',
                                    'error_message': f"–ó–∞–ø—Ä–æ—Å '{query_text}' –Ω–µ –Ω–∞–π–¥–µ–Ω",
                                    'search_mode': search_mode
                                }
                                db.save_monitoring_result(filial['id'], result, session_id)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
                        session_stats['total_tokens_used'] += gigachat_metrics.get('total_tokens', 0)
                else:
                    # –î–ª—è —Ä–µ–∂–∏–º–∞ sitemap_search –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ parsed_content –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π,
                    # —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ—Ç —Ä–µ–∂–∏–º –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç parsed_content
                    if search_mode != "sitemap_search":
                        # –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–æ–≤
                        result = {
                            'filial_id': filial['id'],
                            'url': website,
                            'status': 'error',
                            'error_message': parse_metrics.get('error', '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç–∞')
                        }
                        db.save_monitoring_result(filial['id'], result, session_id)
                        logger.log("ERROR", f"{filial_name}: –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞")
                        session_stats['errors'] += 1
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                progress = (idx + 1) / total_filials
                st.progress(progress)
                
            except Exception as e:
                logger.log("ERROR", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {filial_name}: {str(e)}")
                db.add_log(filial['id'], 'monitoring_error', 'error', str(e))
                session_stats['errors'] += 1
                continue
        
        # –ü–æ–¥—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        session_stats['total_time'] = time.time() - session_start
        if response_times:
            session_stats['avg_response_time'] = sum(response_times) / len(response_times)
        if page_sizes:
            session_stats['avg_page_size'] = sum(page_sizes) / len(page_sizes)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–µ—Å—Å–∏–∏
        logger.log_session_stats(session_stats)
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        st.session_state.processing = False
        st.session_state.current_status = "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω"
        logger.log("INFO", f"‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {session_stats['total_time']:.1f} —Å–µ–∫")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–µ—Å—Å–∏–∏
        if session_id and hasattr(db, 'update_monitoring_session'):
            db.update_monitoring_session(
                session_id,
                filials_count=len(filials),
                queries_count=len(queries),
                results_count=session_stats['successful'],
                status='completed'
            )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ª–æ–≥ –ë–î
        db.add_log(None, 'monitoring_complete', 'success',
                  f'–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ {total_filials} —Ñ–∏–ª–∏–∞–ª–æ–≤, —É—Å–ø–µ—à–Ω–æ {session_stats["successful"]}, –æ—à–∏–±–æ–∫ {session_stats["errors"]}')
        
    except Exception as e:
        logger.log("ERROR", f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        st.session_state.processing = False
        st.session_state.current_status = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é —Å –æ—à–∏–±–∫–æ–π
        if 'session_id' in locals() and session_id and hasattr(db, 'update_monitoring_session'):
            db.update_monitoring_session(
                session_id,
                status='error',
                error_message=str(e)
            )

def show_results_tab(db: VGTRKDatabase):
    """–í–∫–ª–∞–¥–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
    
    # –í—ã–±–æ—Ä —Å–µ—Å—Å–∏–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –ë–î —Å–µ—Å—Å–∏–∏
    if hasattr(db, 'get_monitoring_sessions'):
        sessions = db.get_monitoring_sessions(limit=50)
    else:
        sessions = []
        st.warning("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–µ—Å—Å–∏–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞. –û–±–Ω–æ–≤–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É.")
    
    if sessions:
        col_s1, col_s2 = st.columns([3, 1])
        
        with col_s1:
            session_options = ["–í—Å–µ —Å–µ—Å—Å–∏–∏"] + [
                f"–°–µ—Å—Å–∏—è #{s['id']} –æ—Ç {s.get('started_at', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} ({s.get('search_mode', '–Ω/–¥')}, {s.get('results_count', 0)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)"
                for s in sessions
            ]
            
            selected_session_str = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ—Å—Å–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞",
                session_options,
                help="–§–∏–ª—å—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–µ—Å—Å–∏–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏
            selected_session_id = None
            if selected_session_str != "–í—Å–µ —Å–µ—Å—Å–∏–∏":
                # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ —Å—Ç—Ä–æ–∫–∏ "–°–µ—Å—Å–∏—è #123 –æ—Ç ..."
                import re
                match = re.search(r'–°–µ—Å—Å–∏—è #(\d+)', selected_session_str)
                if match:
                    selected_session_id = int(match.group(1))
        
        with col_s2:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏
            if selected_session_id:
                session_info = next((s for s in sessions if s['id'] == selected_session_id), None)
                if session_info:
                    st.metric("–°—Ç–∞—Ç—É—Å", session_info['status'])
    else:
        selected_session_id = None
        st.info("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Å—Å–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
    
    st.markdown("---")
    
    # –§–∏–ª—å—Ç—Ä—ã
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
        date_filter = st.selectbox(
            "–ü–µ—Ä–∏–æ–¥",
            ["–°–µ–≥–æ–¥–Ω—è", "–í—á–µ—Ä–∞", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π", "–í—Å–µ –≤—Ä–µ–º—è"]
        )
        
        date_from = None
        date_to = None
        
        if date_filter == "–°–µ–≥–æ–¥–Ω—è":
            date_from = datetime.now().strftime("%Y-%m-%d")
            date_to = date_from
        elif date_filter == "–í—á–µ—Ä–∞":
            yesterday = datetime.now() - timedelta(days=1)
            date_from = yesterday.strftime("%Y-%m-%d")
            date_to = date_from
        elif date_filter == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π":
            date_from = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
            date_to = datetime.now().strftime("%Y-%m-%d")
        elif date_filter == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π":
            date_from = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            date_to = datetime.now().strftime("%Y-%m-%d")
    
    with col2:
        # –§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É
        status_filter = st.selectbox(
            "–°—Ç–∞—Ç—É—Å",
            ["–í—Å–µ", "–£—Å–ø–µ—à–Ω–æ", "–û—à–∏–±–∫–∏", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]
        )
        
        status_map = {
            "–£—Å–ø–µ—à–Ω–æ": "success",
            "–û—à–∏–±–∫–∏": "error",
            "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö": "no_data"
        }
        status = status_map.get(status_filter)
    
    with col3:
        # –§–∏–ª—å—Ç—Ä –ø–æ –æ–∫—Ä—É–≥—É
        all_filials = db.get_all_filials()
        districts = sorted(list(set(f['federal_district'] for f in all_filials)))
        districts.insert(0, "–í—Å–µ –æ–∫—Ä—É–≥–∞")
        selected_district = st.selectbox("–û–∫—Ä—É–≥", districts)
    
    with col4:
        # –†–µ–∂–∏–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        display_mode = st.selectbox(
            "–†–µ–∂–∏–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            ["üìä –¢–∞–±–ª–∏—Ü–∞", "üé¥ –ö–∞—Ä—Ç–æ—á–∫–∏"]
        )
    
    # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
    if st.button("üì• –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel", use_container_width='stretch'):
        export_path = f"exports/monitoring_results_{datetime.now():%Y%m%d_%H%M%S}.xlsx"
        Path("exports").mkdir(exist_ok=True)
        db_path = db.export_to_excel(export_path)
        st.success(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {export_path}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    results = db.get_monitoring_results(
        date_from=date_from,
        date_to=date_to,
        status=status,
        session_id=selected_session_id
    )
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –æ–∫—Ä—É–≥—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if selected_district != "–í—Å–µ –æ–∫—Ä—É–≥–∞":
        results = [r for r in results if r.get('federal_district') == selected_district]
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if results:
        st.metric("–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", len(results))
        
        if display_mode == "üé¥ –ö–∞—Ä—Ç–æ—á–∫–∏":
            # –†–µ–∂–∏–º –∫–∞—Ä—Ç–æ—á–µ–∫
            cards_display = ResultsCardsDisplay(results)
            cards_display.display_cards()
        else:
            # –†–µ–∂–∏–º —Ç–∞–±–ª–∏—Ü—ã (—Å—Ç–∞—Ä—ã–π –∫–æ–¥)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
            df = pd.DataFrame(results)
            
            # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            display_columns = ['parsing_date', 'filial_name', 'federal_district',
                              'query_text', 'status', 'gigachat_analysis']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
            available_columns = [col for col in display_columns if col in df.columns]
            df = df[available_columns]
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
            column_names = {
                'parsing_date': '–î–∞—Ç–∞',
                'filial_name': '–§–∏–ª–∏–∞–ª',
                'federal_district': '–û–∫—Ä—É–≥',
                'query_text': '–ó–∞–ø—Ä–æ—Å',
                'status': '–°—Ç–∞—Ç—É—Å',
                'gigachat_analysis': '–ê–Ω–∞–ª–∏–∑'
            }
            df.rename(columns=column_names, inplace=True)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
            if '–î–∞—Ç–∞' in df.columns:
                df['–î–∞—Ç–∞'] = pd.to_datetime(df['–î–∞—Ç–∞']).dt.strftime('%Y-%m-%d %H:%M')
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if '–ê–Ω–∞–ª–∏–∑' in df.columns:
                df['–ê–Ω–∞–ª–∏–∑'] = df['–ê–Ω–∞–ª–∏–∑'].str[:200] + '...'
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
            st.dataframe(
                df,
                use_container_width='stretch',
                hide_index=True
            )
    else:
        st.info("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")

def show_statistics_tab(db: VGTRKDatabase):
    """–í–∫–ª–∞–¥–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    st.header("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
    
    stats = db.get_statistics()
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("–í—Å–µ–≥–æ —Ñ–∏–ª–∏–∞–ª–æ–≤", stats['filials']['total'])
    
    with col2:
        st.metric("–ê–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∏–ª–∏–∞–ª–æ–≤", stats['filials']['active'])
    
    with col3:
        st.metric("–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å–µ–≥–æ–¥–Ω—è", stats['today']['success'])
    
    with col4:
        st.metric("–û—à–∏–±–æ–∫ —Å–µ–≥–æ–¥–Ω—è", stats['today']['errors'])
    
    st.markdown("---")
    
    # –ì—Ä–∞—Ñ–∏–∫–∏
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ–∫—Ä—É–≥–∞–º")
        if stats['by_district']:
            df_districts = pd.DataFrame(
                list(stats['by_district'].items()),
                columns=['–û–∫—Ä—É–≥', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
            )
            st.bar_chart(df_districts.set_index('–û–∫—Ä—É–≥'))
    
    with col2:
        st.subheader("üìà –î–∏–Ω–∞–º–∏–∫–∞ –∑–∞ –Ω–µ–¥–µ–ª—é")
        if stats['last_week']:
            df_week = pd.DataFrame(stats['last_week'])
            if not df_week.empty:
                df_week['date'] = pd.to_datetime(df_week['date'])
                df_week.set_index('date', inplace=True)
                st.line_chart(df_week['count'])
    
    st.markdown("---")
    
    # –¢–æ–ø —Ñ–∏–ª–∏–∞–ª–æ–≤
    st.subheader("üèÜ –¢–æ–ø-5 —Ñ–∏–ª–∏–∞–ª–æ–≤ –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
    if stats['top_filials']:
        df_top = pd.DataFrame(stats['top_filials'])
        df_top.columns = ['–§–∏–ª–∏–∞–ª', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π']
        st.table(df_top)
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏
    st.markdown("---")
    st.subheader("üìù –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è")
    
    logs = db.get_logs(limit=20)
    if logs:
        for log in logs:
            icon = "‚úÖ" if log['status'] == 'success' else "‚ùå"
            time_str = log['created_at'].split('T')[0] if 'T' in log['created_at'] else log['created_at']
            st.text(f"{icon} [{time_str}] {log['action']}: {log['message']}")
    else:
        st.info("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ –ª–æ–≥–∞—Ö")

def show_settings_tab(db: VGTRKDatabase):
    """–í–∫–ª–∞–¥–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∏—Å—Ç–µ–º—ã")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîç –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
        
        # –§–æ—Ä–º–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        with st.form("add_query"):
            st.write("–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
            query_text = st.text_input("–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞")
            category = st.selectbox(
                "–ö–∞—Ç–µ–≥–æ—Ä–∏—è",
                ["–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π", "—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ", "—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ", "–¥—Ä—É–≥–æ–µ"]
            )
            description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ")
            priority = st.slider("–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç", 1, 10, 5)
            
            if st.form_submit_button("–î–æ–±–∞–≤–∏—Ç—å"):
                if query_text:
                    db.add_search_query(query_text, category, description, priority)
                    st.success(f"‚úÖ –ó–∞–ø—Ä–æ—Å '{query_text}' –¥–æ–±–∞–≤–ª–µ–Ω")
                    st.rerun()
        
        # –°–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        st.markdown("---")
        st.write("**–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã:**")
        queries = db.get_search_queries()
        for q in queries:
            col_q1, col_q2 = st.columns([3, 1])
            with col_q1:
                st.text(f"‚Ä¢ {q['query_text']} ({q['category']})")
            with col_q2:
                if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"del_{q['id']}"):
                    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é —É–¥–∞–ª–µ–Ω–∏—è
                    st.warning("–§—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")
    
    with col2:
        st.subheader("üóÑÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ë–î
        db_path = Path("data/vgtrk_monitoring.db")
        if db_path.exists():
            size_mb = db_path.stat().st_size / (1024 * 1024)
            st.metric("–†–∞–∑–º–µ—Ä –ë–î", f"{size_mb:.2f} –ú–ë")
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        st.markdown("---")
        st.write("**–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö**")
        days_to_keep = st.number_input(
            "–•—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (–¥–Ω–µ–π)",
            min_value=7,
            max_value=365,
            value=30
        )
        
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ", use_container_width='stretch'):
            deleted = db.clear_old_results(days_to_keep)
            st.success(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        
        # –≠–∫—Å–ø–æ—Ä—Ç –ø–æ–ª–Ω–æ–π –ë–î
        st.markdown("---")
        if st.button("üíæ –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ–π –ë–î –≤ Excel", use_container_width='stretch'):
            export_path = f"exports/full_database_{datetime.now():%Y%m%d_%H%M%S}.xlsx"
            Path("exports").mkdir(exist_ok=True)
            db.export_to_excel(export_path, include_results=True)
            st.success(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ {export_path}")
        
        # –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
        st.markdown("---")
        if st.button("üîí –°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ë–î", use_container_width='stretch'):
            import shutil
            backup_dir = Path("backups")
            backup_dir.mkdir(exist_ok=True)
            backup_path = backup_dir / f"vgtrk_backup_{datetime.now():%Y%m%d_%H%M%S}.db"
            shutil.copy2(db_path, backup_path)
            st.success(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")

if __name__ == "__main__":
    main()